{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374330d7-848a-43a6-a7a0-c9c3a1e343f8",
   "metadata": {},
   "source": [
    "# CTR prediction with wide and deep model\n",
    "\n",
    "In this notebook, I show how to build a wide and deep model with 3 hidden layers in the deep part of the model. The model is trained 15 epochs using the Avazu CTR prediction dataset. The training yields a log loss of 0.3958 over the test dataset.\n",
    "\n",
    "### Brief introduction of the dataset\n",
    "The dataset I used in this project is the famous [Avazu CTR dataset](https://www.kaggle.com/c/avazu-ctr-prediction) from Kaggle\n",
    "\n",
    "From the overview on the Kaggle page, the data fields in this dataset are:\n",
    "- id: ad identifier\n",
    "- click: 0/1 for non-click/click\n",
    "- hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.\n",
    "- C1 -- anonymized categorical variable\n",
    "- banner_pos\n",
    "- site_id\n",
    "- site_domain\n",
    "- site_category\n",
    "- app_id\n",
    "- app_domain\n",
    "- app_category\n",
    "- device_id\n",
    "- device_ip\n",
    "- device_model\n",
    "- device_type\n",
    "- device_conn_type\n",
    "- C14-C21 -- anonymized categorical variables\n",
    "\n",
    "All features are categorical. This is a binary classification problem where our model need to predict `click` that can be either 0 (no click) or 1 (click).\n",
    "\n",
    "This project can be separated into 2 steps as outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ec751-e330-4f92-b56b-2d9e6344cd3a",
   "metadata": {},
   "source": [
    "### Step 1 - Feature engineering with Spark on K8s\n",
    "\n",
    "In this initial step, I deployed a [spark job](https://github.com/yinanli617/ctr-prediction/blob/master/docker/pyspark-ctr.py) on K8s using the [spark-on-k8s-operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator) to -\n",
    "\n",
    "- Load the raw data;\n",
    "- Generate *wide features* and *deep features*, which will be fed to the model in the next step;\n",
    "- Split the dataset into training set and test set (7:3);\n",
    "\n",
    "#### About the features used\n",
    "\n",
    "1. Wide features:\n",
    "   - All raw features with a number of unique values below 100 are used;\n",
    "   - The following cross-product features are constructed:\n",
    "     - `hr` and `device_type`;\n",
    "     - `device_type` and `app_category`;\n",
    "     - `device_type` and `site_category`;\n",
    "     - `banner_pos` and `device_type`;\n",
    "   - The \"single\" features and the cross-product features are one-hot encoded to generate the wide features (dimension: 475).\n",
    "\n",
    "2. Deep features:\n",
    "   - Embeddings of the following features are generated and fed to the deep part of the model:\n",
    "     - `device_model` (embedding_dim: 256);\n",
    "     - `app_id` (embedding_dim: 256);\n",
    "     - `site_id` (embedding_dim: 256);\n",
    "     - `site_domain` (embedding_dim: 256);\n",
    "     - `app_domain` (embedding_dim: 128);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27dd82-8ffb-4fd2-ab04-8df7b002ccfb",
   "metadata": {},
   "source": [
    "### Step 2 - Training wide and deep model with PyTorch predict CTR\n",
    "\n",
    "***Note: This notebook shows how to train the model on a local laptop equipped with an Nvidia RTX2070 super max-q GPU. A slightly modified version of the codes can be found in `/pytorch_docker/wide_deep_k8s.py` which is used to deploy the pytorch job on Kubernetes. Training on K8s was done on an Nvidia Tesla K80 GPU.***\n",
    "\n",
    "Details about the model architecture:\n",
    "- The deep part of the model contains 3 hidden layers with `hidden_size = [512, 256, 128]`;\n",
    "- Relu is used as activation function in the deep part;\n",
    "- The original [paper](https://arxiv.org/abs/1606.07792) used L1 regularization for the wide part. Here, Adam optimizer is used for both wide and deep parts. However, a dropout layer with `dropout_p=0.7` is added to the wide part before merging with the deep part. The Dropout layer is meant for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136b21dc-9f63-44b8-9316-4984680831b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "import math\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecd9e10-d058-4cfc-ad82-54f4f8428cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "GeForce RTX 2070 Super with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "# During the first step where I extract wanted features in a spark job,\n",
    "# the features that I would like to feed to the deep part of the model\n",
    "# were named as <feature_name>SEP<num_of_unique_values>SEP<embedding_dim>\n",
    "\n",
    "\n",
    "WIDE_DIM = 453\n",
    "COLUMNS = ['label',\n",
    "           'device_modelSEP8251SEP256',\n",
    "           'app_idSEP8552SEP256',\n",
    "           'site_idSEP4737SEP256',\n",
    "           'site_domainSEP7745SEP256',\n",
    "           'app_domainSEP559SEP128',\n",
    "          ]\n",
    "COLUMNS = ['wide_feature_' + str(i) for i in range(WIDE_DIM)] + COLUMNS\n",
    "EMBEDDING_INPUTS = COLUMNS[-5:]\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_WORKERS = 6\n",
    "EPOCHS = 15\n",
    "\n",
    "print(DEVICE)\n",
    "print(torch.cuda.get_device_name(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6001d66-6dbb-4e74-8228-a76631100def",
   "metadata": {},
   "source": [
    "## Define the Wide and Deep Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ea72bb-d70d-48d8-9bf3-e94adf95ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, wide_dim, embedding_inputs, hidden_layers, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.wide_dim = wide_dim\n",
    "        self.embedding_inputs = embedding_inputs\n",
    "        self.deep_feature_dim = 0\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        # For each deep feature, create an embedding layer to convert them to embeddings\n",
    "        for embedding_input in self.embedding_inputs:\n",
    "            col_name, vocab_size, embed_dim = embedding_input.split('SEP')\n",
    "            setattr(self, col_name+'_emb_layer', nn.Embedding(int(vocab_size), int(embed_dim)))\n",
    "            self.deep_feature_dim += int(embed_dim)\n",
    "        \n",
    "        # A series of hidden layers that take the embeddings as input\n",
    "        self.linear_layer_1 = nn.Linear(self.deep_feature_dim, self.hidden_layers[0])\n",
    "        self.bn_1 = nn.BatchNorm1d(self.hidden_layers[0])\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers[1:]):\n",
    "            setattr(self, f'linear_layer_{i+2}', nn.Linear(self.hidden_layers[i], hidden_layer))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # Final dense layer that combine the wide features and the deep features and generate output\n",
    "        self.fc = nn.Linear(self.wide_dim+self.hidden_layers[-1], 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, X_w, X_d):\n",
    "        embeddings = [getattr(self, col_name+'_emb_layer')(X_d[:, i].long())\n",
    "                      for i, embedding_input in enumerate(self.embedding_inputs)\n",
    "                      for col_name in embedding_input.split('SEP')\n",
    "                      if not col_name.isdigit()\n",
    "                     ]\n",
    "        \n",
    "        deep_out = torch.cat(embeddings, dim=-1) # concatenate the embeddings of all deep features\n",
    "        \n",
    "        for i, _ in enumerate(self.hidden_layers):\n",
    "            deep_out = F.relu(getattr(self, f'linear_layer_{i+1}')(deep_out))\n",
    "        \n",
    "        X_w = self.dropout(X_w) # Apply a dropout layer to the wide features for regularization purposes\n",
    "        fc_input = torch.cat([X_w, deep_out], dim=-1) # concatenate the wide and processed deep features\n",
    "        out = self.fc(fc_input)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da2bcd-639a-4bde-9611-1caac7dd2a7c",
   "metadata": {},
   "source": [
    "## Define the Dataset\n",
    "\n",
    "Since the size of the dataset is too big, I use the `pandas` package to read only a chunk of the dataset at each step which can fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a748f2-ff8e-4aaf-98ce-f771228ae294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into <num_workers> parts, so that each worker get a unique copy of a part of the dataset\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n",
    "\n",
    "class CtrDataset(IterableDataset):\n",
    "    def __init__(self, chunksize=10000, train=True):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.num_lines = 28303473 # wc -l ./train_full.csv\n",
    "            self.path = './train_full.csv'\n",
    "        else:\n",
    "            self.num_lines = 12125494 # wc -l ./validation_full.csv\n",
    "            self.path = './validation_full.csv'\n",
    "        self.chunksize = chunksize\n",
    "        self.start = 0\n",
    "        self.end = self.num_lines + self.start - 1\n",
    "    \n",
    "    def process_data(self, data):\n",
    "        for i, chunk in enumerate(data):\n",
    "            if self.start + i*chunk.shape[0] >= self.end:\n",
    "                break\n",
    "            else:\n",
    "                chunk.columns = COLUMNS\n",
    "                \n",
    "                # Don't repeat at the end of each partition\n",
    "                size = min(self.chunksize, self.end - (self.start + i*chunk.shape[0]))\n",
    "                \n",
    "                X_w = chunk.iloc[:size, :WIDE_DIM].values.astype(np.float32).squeeze()\n",
    "                X_d = chunk.iloc[:size][EMBEDDING_INPUTS].values.astype(np.float32).squeeze()\n",
    "                label = chunk.iloc[:size]['label'].values.astype(np.float32).squeeze()\n",
    "                yield X_w, X_d, label\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.df = pd.read_csv(self.path,\n",
    "                             header=None,\n",
    "                             chunksize=self.chunksize,\n",
    "                             skiprows=self.start,\n",
    "                            )\n",
    "        return self.process_data(self.df)\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "    dataset = worker_info.dataset  # the dataset copy in this worker process\n",
    "    overall_start = dataset.start\n",
    "    overall_end = dataset.end\n",
    "    # configure the dataset to only process the split workload\n",
    "    per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))\n",
    "    worker_id = worker_info.id\n",
    "    dataset.start = overall_start + worker_id * per_worker\n",
    "    dataset.end = min(dataset.start + per_worker, overall_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda17415-c0e6-4a8e-ba62-5746a055aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get the total number of batches\n",
    "\n",
    "def get_total(dset, dl):\n",
    "    temp = int(math.ceil((dset.end - dset.start) / float(dl.num_workers))) \n",
    "    total = int(math.ceil(temp / dset.chunksize)) * dl.num_workers\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d9227-ad91-44c7-b6a8-016376eefabc",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393e7c32-f0eb-40fd-876b-0cdb2f8e45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dl, scaler, optimizer, loss_fn, train_total):\n",
    "    pbar = tqdm(train_dl, total=train_total)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    n = 0\n",
    "    for batch_i, (X_w, X_d, label) in enumerate(pbar):\n",
    "        X_w = X_w.squeeze().to(DEVICE, non_blocking=True)\n",
    "        X_d = X_d.squeeze().to(DEVICE, non_blocking=True)\n",
    "        label = label.squeeze().unsqueeze(1).to(DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(X_w, X_d)\n",
    "            loss = loss_fn(outputs, label)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * label.shape[0]\n",
    "        n += label.shape[0]\n",
    "\n",
    "        running_loss = total_loss / n\n",
    "        pbar.set_description(f'Training Loss: {running_loss}')\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5ea36-7367-45ed-be95-7e16128c7e6b",
   "metadata": {},
   "source": [
    "## Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ca1eab-d15e-4deb-8aae-734fa67fa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_dl, loss_fn, val_total):\n",
    "    pbar = tqdm(val_dl, total=val_total)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    n = 0\n",
    "    for batch_i, (X_w, X_d, label) in enumerate(pbar):\n",
    "        X_w = X_w.squeeze().to(DEVICE, non_blocking=True)\n",
    "        X_d = X_d.squeeze().to(DEVICE, non_blocking=True)\n",
    "        label = label.squeeze().unsqueeze(1).to(DEVICE, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad() and torch.cuda.amp.autocast():\n",
    "            outputs = model(X_w, X_d)\n",
    "            loss = loss_fn(outputs, label)\n",
    "            \n",
    "        total_loss += loss.item() * label.shape[0]\n",
    "        n += label.shape[0]\n",
    "\n",
    "        running_loss = total_loss / n\n",
    "        pbar.set_description(f'Validation Loss: {running_loss}')\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008057f3-c531-4442-a3d4-6944efe585d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = WideAndDeep(wide_dim=WIDE_DIM, embedding_inputs=EMBEDDING_INPUTS, hidden_layers=[512, 256, 128],\n",
    "                    dropout_p=0.7,\n",
    "                   )\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=1e-3,\n",
    "    #                              weight_decay=0.01,\n",
    "                                )\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler() # For mixed precision training\n",
    "\n",
    "    lr_scheduler = StepLR(optimizer,\n",
    "                          step_size=5,\n",
    "                          gamma=0.1,\n",
    "                          last_epoch=-1,\n",
    "                          verbose=True,\n",
    "                         )\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        train_dset = CtrDataset(train=True, chunksize=2048)\n",
    "        train_dl = DataLoader(train_dset,\n",
    "                              batch_size=1,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              worker_init_fn=worker_init_fn,\n",
    "                             )\n",
    "        val_dset = CtrDataset(train=False, chunksize=16384)\n",
    "        val_dl = DataLoader(val_dset,\n",
    "                            batch_size=1,\n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            worker_init_fn=worker_init_fn,\n",
    "                           )\n",
    "        train_total = get_total(train_dset, train_dl)\n",
    "        val_total = get_total(val_dset, val_dl)\n",
    "        \n",
    "        print(f'=============== Epoch {epoch} ===============')\n",
    "        train_losses.append(training(model, train_dl, scaler, optimizer, loss_fn, train_total))\n",
    "        val_losses.append(validation(model, val_dl, loss_fn, val_total))\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        print('\\n')\n",
    "        if val_losses[-1] < best_val_loss:\n",
    "            best_val_loss = val_losses[-1] \n",
    "            print('Best model saved.\\n')\n",
    "            torch.save(model.state_dict(), './saved_model.pt')\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634f33a8-c811-4f2f-9533-52fff4f9dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "=============== Epoch 1 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4194596427454083: 100%|██| 13824/13824 [08:03<00:00, 28.59it/s]\n",
      "Validation Loss: 0.4020986238156853: 100%|████| 744/744 [02:56<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 2 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.40841174710943606: 100%|█| 13824/13824 [07:51<00:00, 29.29it/s]\n",
      "Validation Loss: 0.40031580761289776: 100%|███| 744/744 [02:53<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 3 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.40570213808956396: 100%|█| 13824/13824 [08:12<00:00, 28.07it/s]\n",
      "Validation Loss: 0.39906330775334636: 100%|███| 744/744 [02:53<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 4 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.40453960445449244: 100%|█| 13824/13824 [07:56<00:00, 29.04it/s]\n",
      "Validation Loss: 0.39850517347543746: 100%|███| 744/744 [02:53<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 5 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4040050215174234: 100%|██| 13824/13824 [08:11<00:00, 28.15it/s]\n",
      "Validation Loss: 0.3999672847459322: 100%|████| 744/744 [02:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "\n",
      "=============== Epoch 6 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.39644550688678437: 100%|█| 13824/13824 [08:05<00:00, 28.49it/s]\n",
      "Validation Loss: 0.39624556673071915: 100%|███| 744/744 [02:53<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 7 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.396088280741871: 100%|███| 13824/13824 [08:05<00:00, 28.50it/s]\n",
      "Validation Loss: 0.39611545181397784: 100%|███| 744/744 [02:54<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 8 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.39593181454481563: 100%|█| 13824/13824 [08:07<00:00, 28.35it/s]\n",
      "Validation Loss: 0.396045272539394: 100%|█████| 744/744 [02:58<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 9 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.39580195059658735: 100%|█| 13824/13824 [08:16<00:00, 27.85it/s]\n",
      "Validation Loss: 0.39599160531555694: 100%|███| 744/744 [02:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 10 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3956952149506152: 100%|██| 13824/13824 [08:06<00:00, 28.42it/s]\n",
      "Validation Loss: 0.3959455820606816: 100%|████| 744/744 [02:54<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 11 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.39482214411781674: 100%|█| 13824/13824 [08:08<00:00, 28.28it/s]\n",
      "Validation Loss: 0.3958100941001549: 100%|████| 744/744 [02:53<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 12 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3947667585851661: 100%|██| 13824/13824 [08:09<00:00, 28.23it/s]\n",
      "Validation Loss: 0.39578967798484943: 100%|███| 744/744 [02:56<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 13 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.39475172558602667: 100%|█| 13824/13824 [08:10<00:00, 28.19it/s]\n",
      "Validation Loss: 0.3957772384933947: 100%|████| 744/744 [02:57<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 14 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3947477077076388: 100%|██| 13824/13824 [08:14<00:00, 27.96it/s]\n",
      "Validation Loss: 0.39577374951423927: 100%|███| 744/744 [03:07<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n",
      "=============== Epoch 15 ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3947212993513783: 100%|██| 13824/13824 [08:10<00:00, 28.20it/s]\n",
      "Validation Loss: 0.3957672762115228: 100%|████| 744/744 [02:59<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "\n",
      "\n",
      "Best model saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a22780-1f96-423d-a1df-c37055974f4f",
   "metadata": {},
   "source": [
    "## Plot loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42980704-338a-4acf-91a7-32e8f3032745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8589c2-3b0f-41b5-a71f-0cf5b6fdd3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
