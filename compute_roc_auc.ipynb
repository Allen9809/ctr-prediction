{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72af600-4ca6-40c7-a7ed-d43694c5027b",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance and Compute ROC_AUC\n",
    "\n",
    "In this notebook, I will evaluate the performance of the trained wide and deep model by computing the ROC_AUC score on the test dataset. I choose ROC_AUC score as the evaluation metrics because it cares about ranking and the threshold you choose to determine the prediction outcome does not matter. The intuition behind ROC_AUC score is *the probability of a randomly chosen postive target ranking higher than a randomly chosen negative target*.\n",
    "\n",
    "A real-world implementation of the CTR prediction project is to select a handful of applications that the user is most likely to click on. In other words, you don't have to predict the probability of click for all the tens of thousands of applications. You only need to make sure the user is interested in the top ranking handful of applications.\n",
    "\n",
    "The main part of this notebook is copied from the training code. Then we load the saved model and output the predicted probability for each record in the test dataset and compute the ROC_AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a748df13-e810-4369-b994-824f962ac806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score\n",
    "import math\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96392c17-6f66-4fa2-87bd-575155ecedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During the first step where I extract wanted features in a spark job,\n",
    "# the features that I would like to feed to the deep part of the model\n",
    "# were named as <feature_name>SEP<num_of_unique_values>SEP<embedding_dim>\n",
    "\n",
    "\n",
    "WIDE_DIM = 453\n",
    "COLUMNS = ['label',\n",
    "           'device_modelSEP8251SEP256',\n",
    "           'app_idSEP8552SEP256',\n",
    "           'site_idSEP4737SEP256',\n",
    "           'site_domainSEP7745SEP256',\n",
    "           'app_domainSEP559SEP128',\n",
    "          ]\n",
    "COLUMNS = ['wide_feature_' + str(i) for i in range(WIDE_DIM)] + COLUMNS\n",
    "EMBEDDING_INPUTS = COLUMNS[-5:]\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_WORKERS = 6\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a51802b-a0c2-4e56-b649-12c896a000d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, wide_dim, embedding_inputs, hidden_layers, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.wide_dim = wide_dim\n",
    "        self.embedding_inputs = embedding_inputs\n",
    "        self.deep_feature_dim = 0\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        # For each deep feature, create an embedding layer to convert them to embeddings\n",
    "        for embedding_input in self.embedding_inputs:\n",
    "            col_name, vocab_size, embed_dim = embedding_input.split('SEP')\n",
    "            setattr(self, col_name+'_emb_layer', nn.Embedding(int(vocab_size), int(embed_dim)))\n",
    "            self.deep_feature_dim += int(embed_dim)\n",
    "        \n",
    "        # A series of hidden layers that take the embeddings as input\n",
    "        self.linear_layer_1 = nn.Linear(self.deep_feature_dim, self.hidden_layers[0])\n",
    "        self.bn_1 = nn.BatchNorm1d(self.hidden_layers[0])\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers[1:]):\n",
    "            setattr(self, f'linear_layer_{i+2}', nn.Linear(self.hidden_layers[i], hidden_layer))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        \n",
    "        # Final dense layer that combine the wide features and the deep features and generate output\n",
    "        self.fc = nn.Linear(self.wide_dim+self.hidden_layers[-1], 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, X_w, X_d):\n",
    "        embeddings = [getattr(self, col_name+'_emb_layer')(X_d[:, i].long())\n",
    "                      for i, embedding_input in enumerate(self.embedding_inputs)\n",
    "                      for col_name in embedding_input.split('SEP')\n",
    "                      if not col_name.isdigit()\n",
    "                     ]\n",
    "        \n",
    "        deep_out = torch.cat(embeddings, dim=-1) # concatenate the embeddings of all deep features\n",
    "        \n",
    "        for i, _ in enumerate(self.hidden_layers):\n",
    "            deep_out = F.relu(getattr(self, f'linear_layer_{i+1}')(deep_out))\n",
    "        \n",
    "        X_w = self.dropout(X_w) # Apply a dropout layer to the wide features for regularization purposes\n",
    "        fc_input = torch.cat([X_w, deep_out], dim=-1) # concatenate the wide and processed deep features\n",
    "        out = self.fc(fc_input)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552e145a-a02f-431a-b7c4-3bd6a1189174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into <num_workers> parts, so that each worker get a unique copy of a part of the dataset\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset\n",
    "\n",
    "class CtrDataset(IterableDataset):\n",
    "    def __init__(self, chunksize=10000, train=True):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.num_lines = 28303473 # wc -l ./train_full.csv\n",
    "            self.path = './train_full.csv'\n",
    "        else:\n",
    "            self.num_lines = 12125494 # wc -l ./validation_full.csv\n",
    "            self.path = './validation_full.csv'\n",
    "        self.chunksize = chunksize\n",
    "        self.start = 0\n",
    "        self.end = self.num_lines + self.start - 1\n",
    "    \n",
    "    def process_data(self, data):\n",
    "        for i, chunk in enumerate(data):\n",
    "            if self.start + i*chunk.shape[0] >= self.end:\n",
    "                break\n",
    "            else:\n",
    "                chunk.columns = COLUMNS\n",
    "                \n",
    "                # Don't repeat at the end of each partition\n",
    "                size = min(self.chunksize, self.end - (self.start + i*chunk.shape[0]))\n",
    "                \n",
    "                X_w = chunk.iloc[:size, :WIDE_DIM].values.astype(np.float32).squeeze()\n",
    "                X_d = chunk.iloc[:size][EMBEDDING_INPUTS].values.astype(np.float32).squeeze()\n",
    "                label = chunk.iloc[:size]['label'].values.astype(np.float32).squeeze()\n",
    "                yield X_w, X_d, label\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.df = pd.read_csv(self.path,\n",
    "                             header=None,\n",
    "                             chunksize=self.chunksize,\n",
    "                             skiprows=self.start,\n",
    "                            )\n",
    "        return self.process_data(self.df)\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "    dataset = worker_info.dataset  # the dataset copy in this worker process\n",
    "    overall_start = dataset.start\n",
    "    overall_end = dataset.end\n",
    "    # configure the dataset to only process the split workload\n",
    "    per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))\n",
    "    worker_id = worker_info.id\n",
    "    dataset.start = overall_start + worker_id * per_worker\n",
    "    dataset.end = min(dataset.start + per_worker, overall_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29df5c5-def7-460c-8678-8e3102cfb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get the total number of batches\n",
    "\n",
    "def get_total(dset, dl):\n",
    "    temp = int(math.ceil((dset.end - dset.start) / float(dl.num_workers))) \n",
    "    total = int(math.ceil(temp / dset.chunksize)) * dl.num_workers\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80589094-6b21-467c-b9c7-0b65be478648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1481/1481 [07:25<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dset = CtrDataset(train=False, chunksize=8192)\n",
    "val_dl = DataLoader(val_dset,\n",
    "                    batch_size=1,\n",
    "                    num_workers=1,\n",
    "                    worker_init_fn=worker_init_fn,\n",
    "                   )\n",
    "val_total = get_total(val_dset, val_dl)\n",
    "\n",
    "y_true = np.zeros(val_dl.dataset.num_lines)\n",
    "y_proba = np.zeros(val_dl.dataset.num_lines)\n",
    "\n",
    "model = WideAndDeep(wide_dim=WIDE_DIM, embedding_inputs=EMBEDDING_INPUTS, hidden_layers=[512, 256, 128],\n",
    "                    dropout_p=0.7,\n",
    "                   )\n",
    "model.load_state_dict(torch.load('./saved_model.pt')) # load the weights from trained model (15 epochs)\n",
    "\n",
    "pbar = tqdm(val_dl, total=val_total)\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "for batch_i, (X_w, X_d, label) in enumerate(pbar):\n",
    "    X_w = X_w.squeeze().to(DEVICE, non_blocking=True)\n",
    "    X_d = X_d.squeeze().to(DEVICE, non_blocking=True)\n",
    "    label = label.squeeze().unsqueeze(1).to(DEVICE, non_blocking=True)\n",
    "    start = batch_i * val_dset.chunksize\n",
    "    end = start + label.shape[0]\n",
    "\n",
    "    with torch.no_grad() and torch.cuda.amp.autocast():\n",
    "        outputs = model(X_w, X_d)\n",
    "        proba = torch.sigmoid(outputs)\n",
    "\n",
    "    y_true[start:end] = label.squeeze().detach().cpu().numpy()\n",
    "    y_proba[start:end] = proba.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf1dd8-a4d8-410b-a773-d48e19140032",
   "metadata": {},
   "source": [
    "The ROC_AUC score of the wide and deep model is 0.7497, which is ~5.4% improvement from gradient boosting tree model (0.7112)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163ae824-23eb-4360-9e50-525d2d932622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7496930952066014"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a9419-acf2-43fa-9ef4-36484b436523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
